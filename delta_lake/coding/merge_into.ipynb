{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Libraries",
   "id": "2141be0bbdec75e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:22:59.086430Z",
     "start_time": "2025-07-11T22:22:58.982097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip"
   ],
   "id": "89d7592eef768f57",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Spark Session with Delta",
   "id": "e61edc98f361deb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:23:10.768627Z",
     "start_time": "2025-07-11T22:23:05.642552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ],
   "id": "63daa2355bfca00b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/Users/sahilnagpal/Library/Python/3.9/lib/python/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/sahilnagpal/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /Users/sahilnagpal/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d50019f0-4e18-405b-92b8-55907e3bedbf;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.13/4.0.0/delta-spark_2.13-4.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-spark_2.13;4.0.0!delta-spark_2.13.jar (208ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-storage/4.0.0/delta-storage-4.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-storage;4.0.0!delta-storage.jar (32ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.13.1/antlr4-runtime-4.13.1.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.13.1!antlr4-runtime.jar (69ms)\n",
      ":: resolution report :: resolve 1109ms :: artifacts dl 314ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   3   |   3   |   0   ||   3   |   3   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d50019f0-4e18-405b-92b8-55907e3bedbf\n",
      "\tconfs: [default]\n",
      "\t3 artifacts copied, 0 already retrieved (7933kB/14ms)\n",
      "25/07/11 18:23:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b61e735a59d57f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### existing data",
   "id": "cf4202628062ee69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:24:45.891924Z",
     "start_time": "2025-07-11T22:24:39.895978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = [\n",
    "    (1, \"Alice\", \"active\"),\n",
    "    (2, \"Bob\", \"inactive\"),\n",
    "    (3, \"Charlie\", \"active\")\n",
    "]\n",
    "\n",
    "columns = [\"user_id\", \"name\", \"status\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/Users/sahilnagpal/Desktop/wordsToSpeak/delta_lake/dataset/delta_data/\")"
   ],
   "id": "bf3756c99cd898f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:25:25.705533Z",
     "start_time": "2025-07-11T22:25:25.568221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE user_profiles\n",
    "USING DELTA\n",
    "LOCATION '/Users/sahilnagpal/Desktop/wordsToSpeak/delta_lake/dataset/delta_data/';\n",
    "\"\"\")"
   ],
   "id": "12a61f407cda8369",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:26:06.054343Z",
     "start_time": "2025-07-11T22:26:05.389811Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(\"describe detail user_profiles\").show(truncate=False)",
   "id": "f92add863871618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------+-----------------------------------+-----------+--------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name                               |description|location                                                                  |createdAt              |lastModified           |partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+-----------------------------------+-----------+--------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |f5a1e591-0839-4738-9d5d-a05463778ae2|spark_catalog.default.user_profiles|NULL       |file:/Users/sahilnagpal/Desktop/wordsToSpeak/delta_lake/dataset/delta_data|2025-07-11 18:24:41.037|2025-07-11 18:24:43.896|[]              |[]               |3       |3146       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+-----------------------------------+-----------+--------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:26:24.316311Z",
     "start_time": "2025-07-11T22:26:23.681756Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(\"select * from user_profiles\").show(truncate=False)",
   "id": "86f2b1f4f838ec7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|name   |status  |\n",
      "+-------+-------+--------+\n",
      "|3      |Charlie|active  |\n",
      "|2      |Bob    |inactive|\n",
      "|1      |Alice  |active  |\n",
      "+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### new dataset with some changes",
   "id": "c0da12db804aa7c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:30:58.472583Z",
     "start_time": "2025-07-11T22:30:58.432782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "updates = [\n",
    "    (2, \"Bob\", \"inactive\"),       # Update existing user\n",
    "    (4, \"Diana\", \"active\")            # New user\n",
    "]\n",
    "\n",
    "df_updates = spark.createDataFrame(updates, columns)\n",
    "df_updates.createOrReplaceTempView(\"updates_view\")"
   ],
   "id": "70e717e151f5a485",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:30:59.551033Z",
     "start_time": "2025-07-11T22:30:59.471259Z"
    }
   },
   "cell_type": "code",
   "source": "df_updates.show()",
   "id": "7cc0e88e158b2fad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+\n",
      "|user_id| name|  status|\n",
      "+-------+-----+--------+\n",
      "|      2|  Bob|inactive|\n",
      "|      4|Diana|  active|\n",
      "+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### perform 'MERGE INTO'",
   "id": "8f7afc8cd2d25a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:31:12.660833Z",
     "start_time": "2025-07-11T22:31:11.509406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark.sql(\"\"\"\n",
    "MERGE INTO user_profiles AS target\n",
    "USING updates_view as source\n",
    "ON target.user_id = source.user_id\n",
    "\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\").show(truncate=False)"
   ],
   "id": "1a1ff2237240513d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|2                |2               |0               |0                |\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T22:31:43.139677Z",
     "start_time": "2025-07-11T22:31:42.740053Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(\"\"\"select * from user_profiles\"\"\").show()",
   "id": "5f952350af0698be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|   name|  status|\n",
      "+-------+-------+--------+\n",
      "|      3|Charlie|  active|\n",
      "|      1|  Alice|  active|\n",
      "|      2|    Bob|inactive|\n",
      "|      4|  Diana|  active|\n",
      "+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a150545480f462"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
