{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Libraries",
   "id": "8bbf5f3a560bd9ec"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-31T21:03:20.323024Z",
     "start_time": "2025-08-31T21:03:20.031525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.functions import initcap"
   ],
   "id": "b6929f83c0995500",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Spark Session with Delta",
   "id": "69b5a10c03e828b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:03:27.106619Z",
     "start_time": "2025-08-31T21:03:21.423722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ],
   "id": "23c51a02b72a6116",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Library/Python/3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/sahilnagpal/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/sahilnagpal/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c224d752-fdc9-4ae8-bcc2-28c23f94591d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 185ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c224d752-fdc9-4ae8-bcc2-28c23f94591d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/10ms)\n",
      "25/08/31 17:03:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/31 17:03:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:03:34.175658Z",
     "start_time": "2025-08-31T21:03:31.201116Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(f\"CREATE DATABASE IF NOT EXISTS demo_db\")",
   "id": "a4cefb894c006df1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reading the data",
   "id": "9122d67a2ca5742"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:04:21.962552Z",
     "start_time": "2025-08-31T21:04:16.992807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = spark.read.parquet(\"/Users/sahilnagpal/Desktop/wordsToSpeak/delta_lake/dataset/invoices_201_99457.parquet\")\n",
    "df.show(5,truncate=False)"
   ],
   "id": "193526bba737c8bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+---+--------+--------+------+--------------+------------+-----------------+-------------+\n",
      "|customer_id|invoice_no|gender|age|category|quantity|price |payment_method|invoice_date|shopping_mall    |_rescued_data|\n",
      "+-----------+----------+------+---+--------+--------+------+--------------+------------+-----------------+-------------+\n",
      "|201        |I885979   |Female|26 |Clothing|3       |900.24|Debit Card    |2021-07-04  |Metrocity        |NULL         |\n",
      "|202        |I810217   |Female|51 |Clothing|3       |900.24|Cash          |2022-01-14  |Metrocity        |NULL         |\n",
      "|203        |I499170   |Female|38 |Toys    |1       |35.84 |Credit Card   |2022-02-20  |Kanyon           |NULL         |\n",
      "|204        |I792963   |Female|59 |Clothing|5       |1500.4|Debit Card    |2022-06-18  |Emaar Square Mall|NULL         |\n",
      "|205        |I311151   |Female|39 |Souvenir|3       |35.19 |Credit Card   |2022-04-27  |Mall of Istanbul |NULL         |\n",
      "+-----------+----------+------+---+--------+--------+------+--------------+------------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:04:59.625369Z",
     "start_time": "2025-08-31T21:04:24.920665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_union = df\n",
    "expected_rows = 20000000 # 20,000,000\n",
    "\n",
    "while df_union.count() <= expected_rows:\n",
    "    df_union = df_union.union(df_union)\n",
    "    print(f\"count: {df_union.count()}\")\n",
    "\n",
    "print(f\"final count: {df_union.count()}\")"
   ],
   "id": "e416dbbd91d9ac94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 198514\n",
      "count: 397028\n",
      "count: 794056\n",
      "count: 1588112\n",
      "count: 3176224\n",
      "count: 6352448\n",
      "count: 12704896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 25409792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:===============================>                      (151 + 8) / 256]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final count: 25409792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:06:36.814477Z",
     "start_time": "2025-08-31T21:05:52.165601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_union\\\n",
    "    .write\\\n",
    "    .format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .saveAsTable(\"demo_db.zorder_ex1\")"
   ],
   "id": "72311a2d33d2db5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:07:50.675882Z",
     "start_time": "2025-08-31T21:07:50.508810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT category,\n",
    "        SUM(price * quantity) as total_sales\n",
    "    FROM demo_db.zorder_ex1\n",
    "    WHERE customer_id = 201\n",
    "    GROUP BY category\n",
    "    \"\"\"\n",
    ")"
   ],
   "id": "e8b11d9dab11b7ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 ms, sys: 2.88 ms, total: 4.92 ms\n",
      "Wall time: 156 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[category: string, total_sales: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:10:10.295211Z",
     "start_time": "2025-08-31T21:08:40.112977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "table = DeltaTable.forName(spark, \"demo_db.zorder_ex1\")\n",
    "table.optimize().executeZOrderBy(\"customer_id\")"
   ],
   "id": "47c3c0af7e27c2d6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:13:11.079324Z",
     "start_time": "2025-08-31T21:13:11.050263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT category,\n",
    "        SUM(price * quantity) as total_sales\n",
    "    FROM demo_db.zorder_ex1\n",
    "    WHERE customer_id = 201\n",
    "    GROUP BY category\n",
    "    \"\"\"\n",
    ")"
   ],
   "id": "835d37e0a279e426",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 ms, sys: 2.14 ms, total: 4.26 ms\n",
      "Wall time: 19.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[category: string, total_sales: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %sql\n",
    "# OPTIMIZE deltacatalog.deltadb.zorder_ex2\n",
    "# WHERE invoice_date = '{current_day - 1}'\n",
    "# ZORDER BY customer_id;"
   ],
   "id": "b381f3de11d57867"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T21:19:31.425200Z",
     "start_time": "2025-08-31T21:19:31.293834Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(\"drop table demo_db.zorder_ex1\")",
   "id": "583a08382b4c7f73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c59d3af0e1f67c69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Z-Ordering in Delta Lake (Apache Spark)\n",
    "\n",
    "#### What is Z-Ordering?\n",
    "- **Z-Ordering** is a technique in Delta Lake to co-locate related data in the same set of files.\n",
    "- It works by **sorting data across multiple columns** and storing them in the same physical files.\n",
    "- Helps with **data skipping** – Spark can read only relevant portions of data instead of scanning entire tables.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Use Z-Ordering?\n",
    "- **Improved Query Performance**: Queries filtering on Z-Ordered columns read fewer files.\n",
    "- **Efficient Data Skipping**: Delta Lake automatically skips irrelevant data blocks using column statistics.\n",
    "- **Better Clustering for Analytical Queries**: Especially useful for large tables with frequent range or equality filters.\n",
    "\n",
    "---\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "OPTIMIZE <table_name>\n",
    "ZORDER BY (<col1>, <col2>, ...);\n",
    "```\n",
    "\n",
    "-- Optimize and cluster table by customer_id\n",
    "```sql\n",
    "OPTIMIZE sales_table\n",
    "ZORDER BY (customer_id);\n",
    "```\n",
    "\n",
    "-- Optimize and cluster data by multiple dimensions\n",
    "```sql\n",
    "OPTIMIZE sales_table\n",
    "ZORDER BY (region, product_category);\n",
    "```\n",
    "---\n",
    "### Best Practices\n",
    "- Z-Order columns that appear frequently in `WHERE` clauses.\n",
    "- Avoid Z-Ordering on high-cardinality columns unless queries filter by ranges.\n",
    "- Combine with periodic `OPTIMIZE` to handle small files before Z-Ordering.\n",
    "---\n",
    "### Limitations\n",
    "- Z-Ordering is a performance optimization, **not a guarantee**.\n",
    "- Requires **Databricks Runtime** and **Delta Lake** (not supported in open-source Delta without Databricks).\n",
    "- Requires additional **compute cost** during `OPTIMIZE`.\n"
   ],
   "id": "f11cf4b319515ded"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed43b7d4c6b6dd2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
