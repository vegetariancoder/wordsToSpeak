{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Libraries",
   "id": "674863a7aa7cf951"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T14:36:47.480598Z",
     "start_time": "2024-10-14T14:36:47.148296Z"
    }
   },
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.functions import initcap"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Spark Session with Delta",
   "id": "3d6874c5c2c93b83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:37:07.860298Z",
     "start_time": "2024-10-14T14:37:01.150966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ],
   "id": "476cb8cd83797654",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Library/Python/3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/sahilnagpal/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/sahilnagpal/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ac226889-da8c-4b0d-9d1d-16196aa857b9;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 222ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ac226889-da8c-4b0d-9d1d-16196aa857b9\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/7ms)\n",
      "24/10/14 10:37:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the data",
   "id": "ff59a4815000c826"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:40:32.890007Z",
     "start_time": "2024-10-14T14:40:32.873291Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(f\"CREATE DATABASE IF NOT EXISTS demo_db\")",
   "id": "57cf35518dd603c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:40:55.023231Z",
     "start_time": "2024-10-14T14:40:51.966970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark.sql('''CREATE OR REPLACE TABLE demo_db.people_time_travel(\n",
    "id INT,\n",
    "firstName STRING,\n",
    "lastName STRING,\n",
    "birthDate STRING)\n",
    "USING DELTA''')\n",
    "\n",
    "# inserting the data\n",
    "spark.sql('''\n",
    "INSERT OVERWRITE TABLE demo_db.people_time_travel\n",
    "SELECT id, fname as firstName, lname as lastName, dob as birthDate\n",
    "FROM JSON.`/Users/sahilnagpal/Desktop/wordsToSpeak/delta_lake/dataset/people.json`\n",
    "''')\n"
   ],
   "id": "bf9deabdf11abd4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:02:11.916560Z",
     "start_time": "2024-10-14T15:02:09.976509Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql('''select * from demo_db.people_time_travel''').show()",
   "id": "26be277183414b6a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+---------+\n",
      "| id|firstName|lastName|birthDate|\n",
      "+---+---------+--------+---------+\n",
      "+---+---------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Describe History of Table",
   "id": "c32ad6010ad97c35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:06:54.542363Z",
     "start_time": "2024-10-14T15:06:54.214690Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql('''DESCRIBE HISTORY demo_db.people_time_travel''').show(truncate=False)",
   "id": "5e0df7b6d7b13e0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+-----------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation              |operationParameters                                                                           |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                              |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+-----------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|9      |2024-10-14 11:06:39.852|NULL  |NULL    |RESTORE                |{version -> 4, timestamp -> NULL}                                                             |NULL|NULL    |NULL     |8          |Serializable  |false        |{numRestoredFiles -> 1, removedFilesSize -> 0, numRemovedFiles -> 0, restoredFilesSize -> 1330, numOfFilesAfterRestore -> 1, tableSizeAfterRestore -> 1330}                                                                                                                                                                   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|8      |2024-10-14 11:01:56.605|NULL  |NULL    |DELETE                 |{predicate -> [\"true\"]}                                                                       |NULL|NULL    |NULL     |7          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 1330, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 226, numDeletionVectorsUpdated -> 0, numDeletedRows -> 4, scanTimeMs -> 226, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}       |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|7      |2024-10-14 10:59:08.683|NULL  |NULL    |RESTORE                |{version -> 4, timestamp -> NULL}                                                             |NULL|NULL    |NULL     |6          |Serializable  |false        |{numRestoredFiles -> 1, removedFilesSize -> 0, numRemovedFiles -> 0, restoredFilesSize -> 1330, numOfFilesAfterRestore -> 1, tableSizeAfterRestore -> 1330}                                                                                                                                                                   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|6      |2024-10-14 10:56:33.69 |NULL  |NULL    |DELETE                 |{predicate -> [\"true\"]}                                                                       |NULL|NULL    |NULL     |5          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 1289, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 292, numDeletionVectorsUpdated -> 0, numDeletedRows -> 3, scanTimeMs -> 289, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}       |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|5      |2024-10-14 10:43:45.65 |NULL  |NULL    |DELETE                 |{predicate -> [\"(firstName#5377 = M David)\"]}                                                 |NULL|NULL    |NULL     |4          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 1330, numCopiedRows -> 3, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1638, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 1298, numAddedFiles -> 1, numAddedBytes -> 1289, rewriteTimeMs -> 339}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|4      |2024-10-14 10:40:54.845|NULL  |NULL    |WRITE                  |{mode -> Overwrite, partitionBy -> []}                                                        |NULL|NULL    |NULL     |3          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1330}                                                                                                                                                                                                                                                                   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|3      |2024-10-14 10:40:52.396|NULL  |NULL    |CREATE OR REPLACE TABLE|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|NULL    |NULL     |2          |Serializable  |false        |{}                                                                                                                                                                                                                                                                                                                            |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|2      |2024-10-14 10:38:25.151|NULL  |NULL    |WRITE                  |{mode -> Overwrite, partitionBy -> []}                                                        |NULL|NULL    |NULL     |1          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1330}                                                                                                                                                                                                                                                                   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|1      |2024-10-14 10:38:20.166|NULL  |NULL    |CREATE OR REPLACE TABLE|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|NULL    |NULL     |0          |Serializable  |false        |{}                                                                                                                                                                                                                                                                                                                            |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "|0      |2024-10-14 10:37:20.979|NULL  |NULL    |CREATE OR REPLACE TABLE|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|NULL    |NULL     |NULL       |Serializable  |true         |{}                                                                                                                                                                                                                                                                                                                            |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.2.0|\n",
      "+-------+-----------------------+------+--------+-----------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Operation on Delta Table",
   "id": "5706b745b5acd5cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Delete the data",
   "id": "68510bc830dad4f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:43:45.907383Z",
     "start_time": "2024-10-14T14:43:43.926127Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql('''delete from demo_db.people_time_travel where firstName =\"M David\"''').show()",
   "id": "4c57d6111c3464f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|                1|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Select and Show Delta Table Based on Version",
   "id": "78bafef29fb3da72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Version As Of",
   "id": "300ed236deeb1b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:58:10.868298Z",
     "start_time": "2024-10-14T14:58:09.142667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark\\\n",
    "    .sql('''select * from demo_db.people_time_travel VERSION AS OF 4''')\\\n",
    "    .show(truncate=False)"
   ],
   "id": "fda5f0665a7f4c48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "|id |firstName|lastName|birthDate |\n",
      "+---+---------+--------+----------+\n",
      "|101|prashant |pandey  |1975-05-26|\n",
      "|102|abdul    |hamid   |1986-12-28|\n",
      "|103|M David  |turner  |1979-08-23|\n",
      "|104|Kailash  |Patil   |1972-09-02|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Timestamp As Of",
   "id": "59349192e78add3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:58:19.638071Z",
     "start_time": "2024-10-14T14:58:17.902632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark\\\n",
    "    .sql('''select * from demo_db.people_time_travel TIMESTAMP AS OF \"2024-10-14 10:43:45.65\" ''')\\\n",
    "    .show(truncate=False)"
   ],
   "id": "2ebbbef569bd6c72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "|id |firstName|lastName|birthDate |\n",
      "+---+---------+--------+----------+\n",
      "|101|prashant |pandey  |1975-05-26|\n",
      "|102|abdul    |hamid   |1986-12-28|\n",
      "|104|Kailash  |Patil   |1972-09-02|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Accidentally Delete the Data of the Table",
   "id": "c92c3d1d8b0becce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:01:56.902631Z",
     "start_time": "2024-10-14T15:01:56.334004Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql('''delete from demo_db.people_time_travel''').show()",
   "id": "fd30a6f962e29ccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|                4|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Restore the Table Using the \"RESTORE COMMAND\"",
   "id": "52c0f3aa954aabf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Spark SQL Code",
   "id": "7d1cdf958a0fe707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:59:11.709340Z",
     "start_time": "2024-10-14T14:59:02.970555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark.sql('''\n",
    "RESTORE TABLE demo_db.people_time_travel VERSION AS OF 4\n",
    "''').show(truncate=False)"
   ],
   "id": "4cd566a0133edbe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------------+-----------------+------------------+------------------+-------------------+\n",
      "|table_size_after_restore|num_of_files_after_restore|num_removed_files|num_restored_files|removed_files_size|restored_files_size|\n",
      "+------------------------+--------------------------+-----------------+------------------+------------------+-------------------+\n",
      "|1330                    |1                         |0                |1                 |0                 |1330               |\n",
      "+------------------------+--------------------------+-----------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:06:47.525157Z",
     "start_time": "2024-10-14T15:06:45.302539Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql('''select * from demo_db.people_time_travel''').show()",
   "id": "e0aad10403d53058",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "| id|firstName|lastName| birthDate|\n",
      "+---+---------+--------+----------+\n",
      "|101| prashant|  pandey|1975-05-26|\n",
      "|102|    abdul|   hamid|1986-12-28|\n",
      "|103|  M David|  turner|1979-08-23|\n",
      "|104|  Kailash|   Patil|1972-09-02|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Dataframe API Code",
   "id": "46acbf41c1ef6c83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:04:20.729073Z",
     "start_time": "2024-10-14T15:04:18.720448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark\\\n",
    "    .read\\\n",
    "    .format(\"delta\")\\\n",
    "    .option(\"versionAsOf\",\"4\")\\\n",
    "    .table(\"demo_db.people_time_travel\")\\\n",
    "    .show(truncate=False)"
   ],
   "id": "59539a6cebed4065",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "|id |firstName|lastName|birthDate |\n",
      "+---+---------+--------+----------+\n",
      "|101|prashant |pandey  |1975-05-26|\n",
      "|102|abdul    |hamid   |1986-12-28|\n",
      "|103|M David  |turner  |1979-08-23|\n",
      "|104|Kailash  |Patil   |1972-09-02|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Restore using DataFrame API",
   "id": "e10022845b587af0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:06:42.028540Z",
     "start_time": "2024-10-14T15:06:35.103620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "people_dt = DeltaTable.forName(spark, \"demo_db.people_time_travel\")\n",
    "people_dt.restoreToVersion(4)"
   ],
   "id": "192e2ad34e48283e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[table_size_after_restore: bigint, num_of_files_after_restore: bigint, num_removed_files: bigint, num_restored_files: bigint, removed_files_size: bigint, restored_files_size: bigint]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a278c3b77db88ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
